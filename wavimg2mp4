#!/usr/bin/env python3
import os
import subprocess
import math
import argparse
from PIL import Image

# Generated using these three prompts, then the argparse
# code adapted so as not to use switches for input, output and image
prompt1 = r"""
python script that takes a wav file, an image file, uses Pillow to resize the
image, then uses ffmpeg to make a video with the wav file as audio and the
static image file as the visual. speed things up by first rendering a 1 minute
(or other specified duration) loop of the image, and then in a second pass
concatenating as many times as needed using ffconcat, to produce the final
video (using -t to ensure the video doesn't exceed the length of the audio)
"""
prompt2 = r"""
could you adapt it to use argparse to allow things like the resolution and
input/output filenames to be specified on the command line
"""

def create_static_video(args):
    # 1. Get audio duration using ffprobe
    duration_cmd = [
        'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1', args.audio
    ]
    try:
        audio_duration = float(subprocess.check_output(duration_cmd))
        print(f"[*] Detected audio duration: {audio_duration:.2f}s")
    except Exception as e:
        print(f"[!] Error detecting audio duration: {e}")
        return

    # 2. Parse Resolution
    try:
        width, height = map(int, args.res.lower().split('x'))
        target_size = (width, height)
    except ValueError:
        print("[!] Invalid resolution format. Use WIDTHxHEIGHT (e.g., 1920x1080).")
        return

    # 3. Resize Image using Pillow (with Letterboxing)
    resized_img_path = "temp_resized_image.png"
    print(f"[*] Resizing image to {args.res}...")
    
    with Image.open(args.image) as img:
        img.thumbnail(target_size, Image.Resampling.LANCZOS)
        new_img = Image.new("RGB", target_size, (0, 0, 0))
        # Center the image on the black canvas
        offset = ((target_size[0] - img.size[0]) // 2, (target_size[1] - img.size[1]) // 2)
        new_img.paste(img, offset)
        new_img.save(resized_img_path)

    # 4. Create the "Seed" clip (The only heavy encoding step)
    seed_clip = "temp_seed.mp4"
    print(f"[*] Generating {args.seed_len}s seed clip...")
    subprocess.run([
        'ffmpeg', '-y', '-loop', '1', '-i', resized_img_path,
        '-c:v', 'libx264', '-t', str(args.seed_len),
        '-pix_fmt', 'yuv420p', '-vf', f'scale={width}:{height}',
        '-preset', 'veryfast', seed_clip
    ], check=True)

    # 5. Create FFCONCAT file
    num_loops = math.ceil(audio_duration / args.seed_len)
    concat_file = "temp_list.txt"
    with open(concat_file, "w") as f:
        for _ in range(num_loops):
            f.write(f"file '{seed_clip}'\n")

    # 6. Final Pass: Concat (Stream Copy) + Audio Mux
    print("[*] Performing lightning-fast concatenation...")
    subprocess.run([
        'ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', concat_file,
        '-i', args.audio, '-c:v', 'copy', '-c:a', 'aac', '-b:a', '192k',
        '-shortest', '-t', str(audio_duration), args.output
    ], check=True)

    # Cleanup
    for tmp in [resized_img_path, seed_clip, concat_file]:
        if os.path.exists(tmp):
            os.remove(tmp)

    print(f"\n[SUCCESS] Video saved as: {args.output}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate a high-speed static image video from audio.")
    
    # Required Arguments
    parser.add_argument("audio", help="Path to input WAV/audio file")
    parser.add_argument("image", help="Path to input image file")
    
    # Optional Arguments
    parser.add_argument("output", help="Output filename (default: output.mp4)")
    parser.add_argument("-r", "--res", default="1920x1080", help="Resolution WIDTHxHEIGHT (default: 1920x1080)")
    parser.add_argument("-s", "--seed_len", type=int, default=60, help="Length of the seed loop in seconds (default: 60)")

    args = parser.parse_args()
    create_static_video(args)
